{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from  scipy import sparse\n",
    "\n",
    "#store matrix G in a compressed sparse matrix format.  P = (D)^-1 * G\n",
    "#Note that sources contain the \"to\" nodes and the targetumns contain \"from\" nodes\n",
    "\n",
    "#Observe len(nodes) + 1 on the return statement that adds one node to the graph\n",
    "def adding_node():\n",
    "    source = []\n",
    "    target = [] \n",
    "    source_target = []\n",
    "    num_of_edges =0\n",
    "    nodes = set([])\n",
    "    with open(\"stanweb.dat\",'r') as f:\n",
    "        for line in f.readlines():\n",
    "            lst = line.split()\n",
    "            node1, node2, weights = int(lst[0])-1,int(lst[1])-1,float(lst[2])\n",
    "            source.append(node1) #storing \"to\" nodes on sources of G\n",
    "            target.append(node2) #storing \"from\" nodes on targetumns of G\n",
    "            num_of_edges += 1 \n",
    "            nodes.add(node1)\n",
    "            nodes.add(node2)\n",
    "          \n",
    "           \n",
    "            \n",
    "    return sparse.csr_matrix(([1]*num_of_edges,(target,source)),shape=(len(nodes)+1,len(nodes)+1))\n",
    "\n",
    "\n",
    "def construct_csr_matrix():\n",
    "    source = []\n",
    "    target = [] \n",
    "    source_target = []\n",
    "    num_of_edges =0\n",
    "    nodes = set([])\n",
    "    weight_dict = {}\n",
    "    with open(\"stanweb.dat\",'r') as f:\n",
    "        for line in f.readlines():\n",
    "            lst = line.split()\n",
    "            node1, node2, weights = int(lst[0])-1,int(lst[1])-1,float(lst[2])\n",
    "            source.append(node1) #storing \"to\" nodes on sources of G\n",
    "            target.append(node2) #storing \"from\" nodes on targetumns of G\n",
    "            num_of_edges += 1 \n",
    "            \n",
    "            nodes.add(node1)\n",
    "            nodes.add(node2)\n",
    "      \n",
    "    return sparse.csr_matrix(([1]*num_of_edges,(target, source)),shape = (len(nodes) + 1,len(nodes) + 1)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Construct initial matrix\n",
    "G = construct_csr_matrix()\n",
    "\n",
    "#Construct matrix with added node\n",
    "G_plus = adding_node()\n",
    "\n",
    "#Dimensions\n",
    "n = G.shape[0]\n",
    "n_plus = G_plus.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The algorithm is based on the formula rank = alpha *ranks/out_degree + (1−alpha)/n\n",
    "def PageRank(G,n, a=0.85, t = 10**-8):\n",
    "    \n",
    "    d = G.sum(axis=0).T #calculate number of outlinks in each node-webpage\n",
    "    \n",
    "    #Initialization\n",
    "    fast_conv = []\n",
    "    ranks = np.ones((n,1))/n #vector\n",
    "    iterations = 0\n",
    "    error = 1\n",
    "    \n",
    "    #Iterating till convergence\n",
    "    while error > t:       \n",
    "        \n",
    "        #try except is used to ignore division with 0 as some outdegrees are zero\n",
    "        try:\n",
    "            new_ranks = G.dot((a*ranks)/ d)  #G.dot(1/d) is the P hat matrix.\n",
    "        except (ZeroDivisionError): \n",
    "            pass  \n",
    "        \n",
    "        #Add the second part of the formula used to correct dangling nodes\n",
    "        new_ranks += (1-a)/n\n",
    "    \n",
    "        #Check which nodes converge on iteration 1\n",
    "        iterations +=1\n",
    "        if iterations<2:\n",
    "            for i in range(len(ranks)):\n",
    "                if abs(ranks[i]-new_ranks[i])< t:\n",
    "                    fast_conv.append([i])\n",
    "                    \n",
    "        #Stop condition\n",
    "        error = np.linalg.norm(ranks-new_ranks)/np.linalg.norm(ranks)  \n",
    "        ranks = new_ranks\n",
    "    return new_ranks, iterations,fast_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Experimental "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nataz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X rank_score: 5.32096032692e-07\n",
      "The ranks before and after the addition of the new node are the same though the ranking_score has slightly change\n"
     ]
    }
   ],
   "source": [
    "#Calculate Pagerank\n",
    "ranks,_,_ = PageRank(G,n, a=0.85, t = 10**-8)\n",
    "ranks_plus,_,_ = PageRank(G_plus,n_plus, a=0.85, t = 10**-8)\n",
    "\n",
    "#Find indices without the new node\n",
    "ranks = np.asarray(ranks).ravel()\n",
    "indices = ranks.argsort()[-n:][::-1]\n",
    "\n",
    "#Find indices with the new node\n",
    "ranks_plus = np.asarray(ranks).ravel()\n",
    "indices_new = ranks_plus.argsort()[-n_plus:][::-1]\n",
    "\n",
    "print(\"X rank_score:\",ranks_plus[-1])\n",
    "\n",
    "\n",
    "#Compare ranks before and after the addition of the new node\n",
    "Flag = True\n",
    "for i in range(n):\n",
    "    if indices[i] != indices_new[i]:\n",
    "        print(\"The ranks are changed\")\n",
    "        Flag = False\n",
    "        \n",
    "if Flag==True:\n",
    "    print(\"The ranks before and after the addition of the new node are the same though the ranking_score has slightly change\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formula of the ranking :\n",
    "rj = Σβ*ri/di + (1-b)/n , where i are the nodes that have links to j\n",
    "\n",
    "The ranking of the new node is:\n",
    "r281904 = (1-0.85) / 281904 = 5,320960326919802e-7\n",
    "\n",
    "As the new node has no outlinks, the rank of i of any i node has the same inlinks as before. Also the addition of one node on a collection of 281903 nodes is too small to affect the ranking of the nodes. So the rankings remain unchanged.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question b\n",
    "\n",
    "Unsatisﬁed with the PageRank of your page X; you create another page Y (with no in-links) that links to X: What are the PageRanks of all the n + 2 pages now? Does the PageRank of X improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adding_node_Y():\n",
    "    source = []\n",
    "    target = [] \n",
    "    source_target = []\n",
    "    num_of_edges =0\n",
    "    nodes = set([])\n",
    "    weight_dict = {}\n",
    "    with open(\"stanweb.dat\",'r') as f:\n",
    "        for line in f.readlines():\n",
    "            lst = line.split()\n",
    "            node1, node2, weights = int(lst[0])-1,int(lst[1])-1,float(lst[2])\n",
    "            source.append(node1) \n",
    "            target.append(node2) \n",
    "            num_of_edges += 1 \n",
    "            nodes.add(node1)\n",
    "            nodes.add(node2)\n",
    "        \n",
    "        #Adding edge of Y\n",
    "        nodes.add(len(nodes))\n",
    "        nodes.add(len(nodes)+1)\n",
    "        \n",
    "        source.append(len(nodes)) #Y =  one node before the end\n",
    "        target.append(len(nodes)+1) #X=last node\n",
    "        \n",
    "        num_of_edges += 1\n",
    "                \n",
    "    return sparse.csr_matrix(([1]*num_of_edges,(target,source)),shape=(len(nodes)+2,len(nodes)+2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nataz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of ranks changes is: 182967\n",
      "The rank of X before the addition of y is: 5.32096032692e-07\n",
      "The rank of X after the addition of y is: 9.84367184923e-07\n"
     ]
    }
   ],
   "source": [
    "# Create graph containing X,Y\n",
    "G_plus_Y = adding_node_Y()\n",
    "\n",
    "#Dimensions\n",
    "nY = G_plus_Y.shape[0]\n",
    "\n",
    "#Calculate Pagerank\n",
    "ranks_plus_Y , _ ,_ = PageRank(G_plus_Y, nY, a=0.85, t = 10**-8)\n",
    "\n",
    "#Find indices with node X\n",
    "ranks_plus = np.asarray(ranks_plus).ravel()\n",
    "indices_new = ranks_plus.argsort()[-n_plus:][::-1]\n",
    "\n",
    "#Find indices with node X and Y\n",
    "ranks_plus_Y = np.asarray(ranks_plus_Y).ravel()\n",
    "indices_Y = ranks_plus_Y.argsort()[-nY:][::-1]\n",
    "\n",
    "#Compare all ranks before and after the addition of the new node\n",
    "Flag = True\n",
    "count_changes = 0\n",
    "for i in range(n_plus-1):\n",
    "    if indices_new[i] != indices_Y[i]:\n",
    "        count_changes += 1\n",
    "        Flag = False\n",
    "        \n",
    "if Flag==True:\n",
    "    print(\"The ranks before and after the addition of the new node are the same\")\n",
    "else:\n",
    "    print(\"The number of ranks changes is:\", count_changes)\n",
    "    \n",
    "#Compare X rank with and without Y\n",
    "rank_x_prev = ranks_plus[-1]\n",
    "rank_x_after = ranks_plus_Y[-1]\n",
    "\n",
    "\n",
    "print(\"The rank of X before the addition of y is:\",rank_x_prev)\n",
    "print(\"The rank of X after the addition of y is:\", rank_x_after)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as observed the rank_score of X after the insertion of Y is increased. Also the ranks of most of the nodes are changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question c: \n",
    "\n",
    "Still unsatisﬁed, you create a third page Z: How should you set up the links on your three pages so as to maximize the PageRank of X?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After inserting Z in order to maximize the rank of X we would have to insert only one link on the webpage of Z to X. If we add more links from Z to other nodes the value of every link on Z will be segmented into the number of links in Z and thus X will receive less rank score.\n",
    "Y also links only X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementation of the above idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Adding_Node_Z():\n",
    "    source = []\n",
    "    target = [] \n",
    "    source_target = []\n",
    "    num_of_edges =0\n",
    "    nodes = set([])\n",
    "    weight_dict = {}\n",
    "    with open(\"stanweb.dat\",'r') as f:\n",
    "        for line in f.readlines():\n",
    "            lst = line.split()\n",
    "            node1, node2, weights = int(lst[0])-1,int(lst[1])-1,float(lst[2])\n",
    "            source.append(node1) \n",
    "            target.append(node2) \n",
    "            num_of_edges += 1 \n",
    "            nodes.add(node1)\n",
    "            nodes.add(node2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #Adding edge of Y\n",
    "        nodes.add(281903) #Y = 281903\n",
    "        nodes.add(281904) #Z = 281904\n",
    "        nodes.add(281905) #X = 281905\n",
    "        \n",
    "        \n",
    "        source.append(281903)\n",
    "        target.append(281905)\n",
    "        \n",
    "        source.append(281904)\n",
    "        target.append(281905)\n",
    "        \n",
    "        num_of_edges += 2\n",
    "       \n",
    "    return sparse.csr_matrix(([1]*num_of_edges,(target,source)),shape=(len(nodes) + 3,len(nodes) + 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It holds that the more the links in a website the less the value of each link for the targeted page.\n",
    "So in order to maximize the value of X we will introduce one link from Y to X and one link from Z to X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nataz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rank of X before introducing Z is: 5.320865953197664e-07\n",
      "The rank of X after introducing Z is: 5.32096032692e-07\n"
     ]
    }
   ],
   "source": [
    "G_plus_ZY = Adding_Node_Z()\n",
    "n_ZY = G_plus_ZY.shape[0]\n",
    "\n",
    "#Calculate Pagerank\n",
    "ranks_plus_Y , _ ,_ = PageRank(G_plus_ZY, n_ZY, a=0.85, t = 10**-8)\n",
    "\n",
    "#Find indices with node X\n",
    "ranks_plus_ZY = np.asarray(ranks_plus).ravel()\n",
    "\n",
    "print(\"The rank of X before introducing Z is:\", float(ranks_plus_Y[-1]))\n",
    "print(\"The rank of X after introducing Z is:\", ranks_plus_ZY[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the results we conclude that adding a link from any page to X increases the X rank but if the webpage is not important the increase in X is small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question d: \n",
    "\n",
    "You have one last idea, you add links from your page X to older, popular pages (e.g.: you add a list of ?Useful links? on your page). Does this improve the PageRank of X? Does the answer change if you add links from Y or Z to older, popular pages? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As power method is a popularity measure I add a link of X  to the top 20 top ranked webpages of the previous question(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function that adds links of top 20 ranked webpages to the webpage of X\n",
    "def Add_links_to_X(source_lst):\n",
    "    source = []\n",
    "    target = [] \n",
    "    num_of_edges =0\n",
    "    nodes = set([])\n",
    "    weight_dict = {}\n",
    "    with open(\"stanweb.dat\",'r') as f:\n",
    "        for line in f.readlines():\n",
    "            lst = line.split()\n",
    "            node1, node2, weights = int(lst[0])-1,int(lst[1])-1,float(lst[2])\n",
    "            source.append(node1) \n",
    "            target.append(node2) \n",
    "            num_of_edges += 1 \n",
    "            nodes.add(node1)\n",
    "            nodes.add(node2)\n",
    "        \n",
    "        #Adding edge of Y and Z\n",
    "        nodes.add(281903)\n",
    "        nodes.add(281904)\n",
    "        nodes.add(281905)\n",
    "        \n",
    "        #Links from Y , Z to X\n",
    "        source.append(281903)\n",
    "        target.append(281905)\n",
    "        \n",
    "        source.append(281904)\n",
    "        target.append(281905)\n",
    "        \n",
    "        num_of_edges += 2\n",
    "        \n",
    "        #Add links to source pages linking to the target page\n",
    "        source.extend([len(nodes)]*len(source_lst))\n",
    "        target.extend(source_lst)\n",
    "        num_of_edges += len(source_lst)\n",
    "        \n",
    "       \n",
    "        \n",
    "    return sparse.csr_matrix(([1]*num_of_edges,(target,source)),shape=(len(nodes)+3,len(nodes)+3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nataz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rank of X before introducing links is: 5.32096032692e-07\n",
      "The rank of X after introducing the links is: 5.3208659532e-07\n"
     ]
    }
   ],
   "source": [
    "#Find top 20 links using power method after the addition of Y, Z\n",
    "indices_plusZY = ranks_plus_ZY.argsort()[-n_ZY:][::-1]\n",
    "\n",
    "#Add link to X from top 20 ranked pages\n",
    "G_d = Add_links_to_X(indices_plusZY[:20])\n",
    "\n",
    "ranks_d , _ ,_ = PageRank(G_d, G_d.shape[0], a=0.85, t = 10**-8)\n",
    "ranks_d = np.asarray(ranks_d).ravel()\n",
    "print(\"The rank of X before introducing links is:\", ranks_plus_ZY[-1])\n",
    "print(\"The rank of X after introducing the links is:\", ranks_d[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding links of Y to top ranked pages of previous question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function that adds links of Y to the 20 top ranked websites of question c\n",
    "def Add_links_of_Y(source_lst):\n",
    "    source = []\n",
    "    target = [] \n",
    "    num_of_edges =0\n",
    "    nodes = set([])\n",
    "    weight_dict = {}\n",
    "    with open(\"stanweb.dat\",'r') as f:\n",
    "        for line in f.readlines():\n",
    "            lst = line.split()\n",
    "            node1, node2, weights = int(lst[0])-1,int(lst[1])-1,float(lst[2])\n",
    "            source.append(node1) \n",
    "            target.append(node2) \n",
    "            num_of_edges += 1 \n",
    "            nodes.add(node1)\n",
    "            nodes.add(node2)\n",
    "        \n",
    "        #Adding edge of Y and Z\n",
    "        nodes.add(281903)\n",
    "        nodes.add(281904)\n",
    "        nodes.add(281905)\n",
    "        \n",
    "        #Links from Y , Z to X\n",
    "        source.append(281903)\n",
    "        target.append(281905)\n",
    "        \n",
    "        source.append(281904)\n",
    "        target.append(281905)\n",
    "        \n",
    "        num_of_edges += 2\n",
    "        \n",
    "        #Add links to source pages linking to the target page\n",
    "        source.extend([281904]*len(source_lst))\n",
    "        target.extend(source_lst)\n",
    "        num_of_edges += len(source_lst)\n",
    "          \n",
    "    return sparse.csr_matrix(([1]*num_of_edges,(target,source)),shape=(len(nodes)+3,len(nodes)+3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nataz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rank of X before introducing links is: 5.32096032692e-07\n",
      "The rank of X after introducing the links is: 5.3208659532e-07\n"
     ]
    }
   ],
   "source": [
    "#Add link to X from top 20 ranked pages\n",
    "G_d = Add_links_of_Y(indices_plusZY[:20])\n",
    "\n",
    "ranks_d , _ ,_ = PageRank(G_d, G_d.shape[0], a=0.85, t = 10**-8)\n",
    "ranks_d = np.asarray(ranks_d).ravel()\n",
    "print(\"The rank of X before introducing links is:\", ranks_plus_ZY[-1])\n",
    "print(\"The rank of X after introducing the links is:\", ranks_d[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that introducing more links to X or to Y does not change the outcome of the power method. The rankings remain the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question e \n",
    "\n",
    "Describe what steps you might take to raise the PageRank of X further. You do not need to prove anything here, just summarize your thoughts based on the previous parts. For extra credit though, you can prove what the structure for a link farm with m nodes should be to optimize the PageRank of X.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In question b,c we added links from Y to X and from Z to X and observed that this action increased the ranking of X. We also know from bibliography that if the pages that contain links to X are top ranked then this will add more value to the ranking of X. Therefore we have to work towards the creation of links of X into other top ranked pages. It is important to highlight that the addition of links of other pages into our page X as done in question d  did not contribute to the ranking of X."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

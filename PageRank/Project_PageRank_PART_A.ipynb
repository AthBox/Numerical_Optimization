{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from  scipy import sparse\n",
    "import time\n",
    "\n",
    "#store matrix G in a compressed sparse matrix format.  P = (D)^-1 * G\n",
    "#Note that rows contain the \"to\" nodes and the columns contain \"from\" nodes\n",
    "def data_to_csr():\n",
    "    row = []\n",
    "    col = [] \n",
    "    row_col = []\n",
    "    num_of_edges =0\n",
    "    nodes = set([])\n",
    "    weight_dict = {}\n",
    "    with open(\"stanweb.dat\",'r') as f:\n",
    "        for line in f.readlines():\n",
    "            lst = line.split()\n",
    "            node1, node2, weights = int(lst[0])-1,int(lst[1])-1,float(lst[2])\n",
    "            row.append(node1) #storing \"to\" nodes on rows of G\n",
    "            col.append(node2) #storing \"from\" nodes on columns of G\n",
    "            num_of_edges += 1 \n",
    "            nodes.add(node1)\n",
    "            nodes.add(node2)\n",
    "            weight_dict[node1] = weights #creating outdegrees dictionary\n",
    "        \n",
    "        #inserting nodes with outdegree 0 on the out degree dictionary\n",
    "        for node in nodes:\n",
    "            if node not in weight_dict.keys():\n",
    "                weight_dict[node] = [0]\n",
    "                \n",
    "    return sparse.csr_matrix(([1]*num_of_edges,(col,row)),shape=(len(nodes),len(nodes))), weight_dict\n",
    "\n",
    "#constructing dictionary where keys are the nodes2 of the file and values are the nodes that contain links to the key\n",
    "def construct_giving_list():\n",
    "    nodes=set([])\n",
    "    out_list = {}\n",
    "    with open(\"stanweb.dat\",'r') as f:\n",
    "        for line in f.readlines():\n",
    "            lst = line.split()\n",
    "            node1, node2, weights = int(lst[0])-1,int(lst[1])-1, float(lst[2])\n",
    "            nodes.add(node1)\n",
    "            nodes.add(node2)\n",
    "            try:\n",
    "                out_list[node2].append(node1)\n",
    "            except:\n",
    "                out_list[node2]=[node1]\n",
    "                \n",
    "        for node in nodes:\n",
    "            if node not in out_list.keys():\n",
    "                out_list[node]=[]\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create matrices that will be used below\n",
    "G, out_degree = data_to_csr() #G is sparse compressed matrix, outdegree is a dictionary\n",
    "n = G.shape[0] #number of nodes\n",
    "giving_pages = construct_giving_list() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Page Rank Implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following function I implement the pagerank algorithm according to Google's algorithm using the formula:\n",
    "\n",
    "x(k).T=x(k-1).T*P + (1-α)*v.T \n",
    " \n",
    " I manipulated the implementation of the power method of the paper as it was impossible to create (1-α)*v.T due to memory error. So I first calculate a* x(k-1) *P  excluding dangling nodes and then add (1-a)/n to all the nodes including dangling ones to avoid storing vector v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The algorithm is based on the formula rank = alpha *ranks/out_degree + (1−alpha)/n\n",
    "def PageRank(G,n, a=0.85, t = 10**-8):\n",
    "    \n",
    "    d = G.sum(axis=0).T #calculate number of outlinks in each node-webpage\n",
    "    \n",
    "    #Initialization\n",
    "    fast_conv = []\n",
    "    ranks = np.ones((n,1))/n #vector\n",
    "    iterations = 0\n",
    "    error = 1\n",
    "    \n",
    "    #Iterating till convergence\n",
    "    while error > t:       \n",
    "        #try except is used to ignore division with 0 as some outdegrees are zero\n",
    "        try:\n",
    "            new_ranks = G.dot(a*(ranks/ d))  #G.dot(1/d) is the P hat matrix.\n",
    "        except (ZeroDivisionError): \n",
    "            pass  \n",
    "        \n",
    "        #Add the second part of the formula used to correct dangling nodes\n",
    "        new_ranks += (1-a)/n\n",
    "    \n",
    "        #Check which nodes converge on iteration 1\n",
    "        iterations +=1\n",
    "        if iterations<2:\n",
    "            for i in range(len(ranks)):\n",
    "                if np.linalg.norm(ranks[i]-new_ranks[i])< t:\n",
    "                    fast_conv.append([i])\n",
    "                    \n",
    "        #Stop condition\n",
    "        error = np.linalg.norm(ranks-new_ranks)/np.linalg.norm(ranks)  \n",
    "        ranks = new_ranks\n",
    "    return new_ranks, iterations,fast_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gauss Seidel Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This implementation is based on the paper http://www.w3c.ethz.ch/CDstore/www2002/poster/173.pdf on the formula on page 3\n",
    "def Gauss_Seidel(G,outdegree,a,n,threshold = 10**-8):\n",
    "    rank_prev = np.ones(n)/n\n",
    "    iterations = 0\n",
    "    fast_conv=[]\n",
    "    err = 1\n",
    "    rank = rank_prev.copy()\n",
    "    flag = False\n",
    "   \n",
    "    while flag == False:\n",
    "        iterations +=1        \n",
    "        for i in range(n):\n",
    "            summation1 = 0\n",
    "            summation2 = 0\n",
    "            for j in G[i]:\n",
    "                if j < i:                                          \n",
    "                    summation1 += a *outdegree[j] * rank[j]\n",
    "                if j > i:                                          \n",
    "                    summation2 +=  a * outdegree[j] * rank_prev[j]\n",
    "            rank[i] = (1-a) + summation1 + summation2\n",
    "\n",
    "        err = np.linalg.norm(rank - rank_prev)/np.linalg.norm(rank)\n",
    "        if err < threshold:\n",
    "            flag = True\n",
    "        \n",
    "        \n",
    "        if iterations<2:\n",
    "            for i in range(len(rank)):\n",
    "                if np.linalg.norm(rank[i]- rank_prev[i])< threshold:\n",
    "                    fast_conv.append([i])\n",
    "        rank_prev = rank.copy()\n",
    "        \n",
    "    return rank,iterations,fast_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question a:  Are the results the same for both methods? Which method seems to be faster? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate Pagerank using Gauss Seidel for a=0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to execute: 2.8148815274238586 minutes\n",
      "\n",
      "The 20 max ranked nodes are:\n",
      "[ 89072 226410 241453 262859 134831 234703 136820  68888 105606  69357\n",
      "  67755 225871 186749 272441 251795  95162 119478 231362  55787 167294\n",
      " 179644  38341 117151 198089  60209 235495 132694 181700 259454 247240\n",
      " 120707  62477 161889 221086 183003 176789 137631  77998  17780  96744\n",
      " 112741 145891 151427  81434  60439 208541     90 214127 258347 222872]\n",
      "\n",
      "Number of iterations: 57\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#linking_pages, in_degree_values = construct_indegree_list()\n",
    "start = time.time()\n",
    "results_gs,iterations,_ = Gauss_Seidel(giving_pages,out_degree ,0.85,n,10**-8)\n",
    "end = time.time()\n",
    "print(\"Time to execute:\" ,(end-start)/60, \"minutes\")\n",
    "indices_gs_85 = results_gs.argsort()[-n:][::-1]\n",
    "print(\"\\nThe 20 max ranked nodes are:\")\n",
    "print(indices_gs_85[:50])\n",
    "print(\"\\nNumber of iterations:\", iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate Pagerank using Power Method for a=0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nataz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to execute: 4.942476511001587 seconds\n",
      "\n",
      "The 20 max ranked nodes are:\n",
      "[ 89072 226410 241453 262859 134831 234703 136820  68888 105606  69357\n",
      "  67755 225871 186749 251795 272441  95162 119478 231362  55787 167294\n",
      " 179644  38341 117151 198089  60209 235495 132694 181700 247240 259454\n",
      " 120707  62477 161889  17780 176789 221086  77998 183003 137631  96744\n",
      " 112741 145891 151427  81434  60439 208541     90 214127 258347 222872]\n",
      "\n",
      "Number of iterations: 95\n"
     ]
    }
   ],
   "source": [
    "start =  time.time()\n",
    "ranks,iterations, _ = PageRank(G,n, a=0.85, t = 10**-8)\n",
    "end = time.time()\n",
    "#Get indices of the max ranked\n",
    "ranks = np.asarray(ranks).ravel()\n",
    "indices_pr_85 = ranks.argsort()[-n:][::-1]\n",
    "print(\"Time to execute:\",end-start,\"seconds\")\n",
    "print(\"\\nThe 20 max ranked nodes are:\")\n",
    "print(indices_pr_85[:50])\n",
    "print(\"\\nNumber of iterations:\", iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes ranked significantly differently(more than 5 positions difference) are: 57977\n"
     ]
    }
   ],
   "source": [
    "#Compare results\n",
    "flag = True\n",
    "counter=0\n",
    "k = 5 #check if the ranking of a node using gauss seidel is the same with the rank of that node +-5 positions using Power Method\n",
    "for i in range(len(indices_gs_85)-k) :\n",
    "    if indices_pr_85[i] not in indices_gs_85[i-k : i+k]:\n",
    "        flag = False\n",
    "        counter += 1\n",
    "if flag==True:\n",
    "    print(\"The results are the same for both methods\")\n",
    "else:\n",
    "    print(\"The number of nodes ranked significantly differently(more than 5 positions difference) are:\", counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "The results are the not exactly the same for Pagerank and Gauss Seidel but while observing the 50 most important results we can refer that the rankings differ for only one to 5 positions for most nodes.\n",
    "\n",
    "Speed: \n",
    "Pagerank is significantly faster as it is possible to use dot products. But it is important to note that in bibliography it is mentioned that Gauss Seidel can be faster in some types of matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question b :Do the previous task with α = 0.99.Your remarks on the convergence speed. Did the ranking of the ﬁrst 50 nodes changed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run Gauss Seidel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to execute: 24.674164497852324 minutes\n",
      "\n",
      "The 20 max ranked nodes are:\n",
      "[ 89072 281771 174664 226410 179644 271408 262859 136820  68888  77987\n",
      " 116529 272441 251795  95162  65579 119478 241453 245764  58047  14784]\n"
     ]
    }
   ],
   "source": [
    "#linking_pages, in_degree_values = construct_indegree_list()\n",
    "start = time.time()\n",
    "results_gs,_,_ = Gauss_Seidel(giving_pages,out_degree ,0.99,n,10**-8)\n",
    "end = time.time()\n",
    "print(\"Time to execute:\" ,(end-start)/60, \"minutes\")\n",
    "indices_gs = results_gs.argsort()[-n:][::-1]\n",
    "print(\"\\nThe 20 max ranked nodes are:\")\n",
    "print(indices_gs[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate using Power Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nataz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to execute: 68.7914092540741 seconds\n",
      "\n",
      "The 20 max ranked nodes are:\n",
      "[ 89072 281771 174664 226410 179644 271408 262859 136820  68888  77987\n",
      " 116529 272441  95162 251795  65579 119478 241453 245764  58047  14784]\n",
      "\n",
      "Number of iterations: 1514\n"
     ]
    }
   ],
   "source": [
    "#Calculate using Power Method\n",
    "start =  time.time()\n",
    "ranks,iterations, _ = PageRank(G,n, a=0.99, t = 10**-8)\n",
    "end = time.time()\n",
    "\n",
    "#Get indices of the max ranked\n",
    "ranks = np.asarray(ranks).ravel()\n",
    "indices_b = ranks.argsort()[-n:][::-1]\n",
    "\n",
    "print(\"Time to execute:\",end-start,\"seconds\")\n",
    "print(\"\\nThe 20 max ranked nodes are:\")\n",
    "print(indices_b[:20])\n",
    "print(\"\\nNumber of iterations:\", iterations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare top 50 nodes of Power method with a=0.85 to the top 50 of the power method with a = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of top 50 ranked pages significantly differently are: 48\n"
     ]
    }
   ],
   "source": [
    "flag = True\n",
    "counter=0\n",
    "for i in range(50) :\n",
    "    if indices_b[i] != indices_pr_85[i]:\n",
    "        flag = False\n",
    "        counter += 1\n",
    "if flag==True:\n",
    "    print(\"The results are the same for both methods\")\n",
    "else:\n",
    "    print(\"The number of top 50 ranked pages significantly differently are:\", counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Compare top 50 nodes of Gauss Seidel with a=0.85 to the top 50 of the Gauss Seidel with a = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of top 50 ranked pages significantly differently are: 49\n"
     ]
    }
   ],
   "source": [
    "flag = True\n",
    "counter=0\n",
    "for i in range(50) :\n",
    "    if indices_gs[i] != indices_gs_85[i]:\n",
    "        flag = False\n",
    "        counter += 1\n",
    "if flag==True:\n",
    "    print(\"The results are the same for both methods\")\n",
    "else:\n",
    "    print(\"The number of top 50 ranked pages significantly differently are:\", counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power method for a=0.88 runs in 5 seconds while the one with a=0.99 runs in approximatelly 40 seconds. \n",
    "Gauss Seidel with a=0.85 converges in 3 minutes while gauss seidel with a=0.99 converges in 45 minutes.\n",
    "\n",
    "This delay of convergence happens because 1-a which is the probability of teleportation to another non-connected node is too small and thus the surfer stays trapped into spider traps and deadlocks for many iterations.  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question C : When we use the power method do all the cmponents of π converge at the same speed to their limits? If not which of the converge faster: those that correspond to important nodes or to non important ? Do you observe the same behavior when you ﬁnd π through the solution of the linear system?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Power Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nataz\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The  number of nodes that had already converged from the first iteration is: 14542\n",
      "\n",
      "Not one of the 100 highly ranked nodes converged on the first iteration.\n"
     ]
    }
   ],
   "source": [
    "#Power Method\n",
    "ranks,iterations, conv_results = PageRank(G,n, a=0.85, t = 10**-8)\n",
    "\n",
    "#Get indices of the max ranked\n",
    "ranks = np.asarray(ranks).ravel()\n",
    "indices = ranks.argsort()[-G.shape[0]:][::-1]\n",
    "\n",
    "print(\"The  number of nodes that had already converged from the first iteration is:\", len(conv_results))\n",
    "\n",
    "#Check if any of the first 100 highly ranked nodes are in the list of the nodes that converged in the first iteration\n",
    "flag = False\n",
    "for ind in indices[:100]:\n",
    "    if ind in conv_results:\n",
    "        print(\"The important nodes(top 100) that converged on iteration 1 are:\",ind)\n",
    "        flag = True\n",
    "\n",
    "if flag == False:\n",
    "    print(\"\\nNot one of the 100 highly ranked nodes converged on the first iteration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gauss Seidel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The  number of nodes that had already converged from the first iteration is: 0\n",
      "\n",
      "Not one of the 100 highly ranked nodes converged on the first iteration.\n"
     ]
    }
   ],
   "source": [
    "ranks,iterations, conv_results = Gauss_Seidel(giving_pages,out_degree ,0.85,n,10**-8)\n",
    "\n",
    "#Get indices of the max ranked\n",
    "ranks = np.asarray(ranks).ravel()\n",
    "indices = ranks.argsort()[-G.shape[0]:][::-1]\n",
    "\n",
    "print(\"The  number of nodes that had already converged from the first iteration is:\", len(conv_results))\n",
    "\n",
    "#Check if any of the first 100 highly ranked nodes are in the list of the nodes that converged in the first iteration\n",
    "flag = False\n",
    "for ind in indices[:100]:\n",
    "    if ind in conv_results:\n",
    "        print(\"The important nodes(top 100) that converged on iteration 1 are:\",ind)\n",
    "        flag = True\n",
    "\n",
    "if flag == False:\n",
    "    print(\"\\nNot one of the 100 highly ranked nodes converged on the first iteration.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
